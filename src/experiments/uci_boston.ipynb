{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from copy import deepcopy\n",
    "import os\n",
    "os.chdir(\"/home/jakob/doktor/projects/EnsembleUncertainty/code\")\n",
    "\"\"\"Learing \"logit\" distribution in regression example\"\"\"\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import logging\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "\n",
    "import src.dataloaders.uci.bost as uci_bost\n",
    "import src.utils as utils\n",
    "from src.distilled import logits_probability_distribution\n",
    "from src.ensemble import ensemble\n",
    "from src.ensemble import sep_regressor, mean_regressor, simple_regressor\n",
    "import src.metrics as metrics\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "EXPERIMENT_NAME = \"regression_logits\"\n",
    "\n",
    "# Settings\n",
    "class Args():\n",
    "    pass\n",
    "args = Args()\n",
    "args.seed = 1\n",
    "args.gpu = False\n",
    "args.log_dir = Path(\"./logs\")\n",
    "args.log_level = logging.INFO\n",
    "args.retrain = True\n",
    "\n",
    "args.num_ensemble_members=10\n",
    "args.num_epochs=100\n",
    "args.lr = 0.01\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_plots(distilled_model, data):\n",
    "    test_loader = torch.utils.data.DataLoader(data,\n",
    "                                              batch_size=16,\n",
    "                                              shuffle=True,\n",
    "                                              num_workers=0)\n",
    "\n",
    "    predictions = np.zeros((data.n_samples, distilled_model.output_size))\n",
    "    all_x = np.zeros((data.n_samples, 1))\n",
    "    all_y = np.zeros((data.n_samples, 1))\n",
    "\n",
    "    idx = 0\n",
    "    for batch in test_loader:\n",
    "        inputs, targets = batch\n",
    "\n",
    "        predictions[idx * test_loader.batch_size:(idx + 1) * test_loader.batch_size, :, :] = \\\n",
    "            distilled_model.predict(inputs, t=None).data.numpy()\n",
    "\n",
    "        all_x[idx * test_loader.batch_size:(idx + 1) *\n",
    "              test_loader.batch_size, :] = inputs\n",
    "        all_y[idx * test_loader.batch_size:(idx + 1) *\n",
    "              test_loader.batch_size, :] = targets\n",
    "\n",
    "        idx += 1\n",
    "\n",
    "    plt.scatter(np.squeeze(all_x), np.squeeze(all_y), label=\"Data\", marker=\".\")\n",
    "\n",
    "    plt.errorbar(np.squeeze(all_x),\n",
    "                 predictions[:, 0],\n",
    "                 np.sqrt(predictions[:, 1]),\n",
    "                 label=\"Distilled model predictions\",\n",
    "                 marker=\".\",\n",
    "                 ls=\"none\")\n",
    "\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 14:48:06,452 INFO  root            - Log at /home/jakob/doktor/projects/EnsembleUncertainty/code/logs/regression_logits_20200113_144806.log\n",
      "2020-01-13 14:48:06,452 INFO  __main__        - Args: <__main__.Args object at 0x7f3705a64588>\n",
      "2020-01-13 14:48:06,454 INFO  __main__        - Creating dataloader\n",
      "2020-01-13 14:48:06,458 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:48:06,459 WARNING Ensemble        - Is subclass check disabled\n",
      "2020-01-13 14:48:06,460 INFO  Ensemble        - Adding <class 'src.ensemble.mean_regressor.MeanRegressor'> to ensemble\n",
      "2020-01-13 14:48:06,461 INFO  Ensemble        - Adding metric: RMSE\n",
      "2020-01-13 14:48:06,462 INFO  Ensemble        - Training ensemble\n",
      "2020-01-13 14:48:06,463 INFO  Ensemble        - Training member 1/1\n",
      "2020-01-13 14:48:06,463 WARNING src.metrics     - Trying to calculate mean on unpopulated metric.\n",
      "2020-01-13 14:48:06,492 INFO  MeanRegressor   - Train - Epoch 1: Loss: 1112.247 RMSE: 30.962\n",
      "2020-01-13 14:48:06,494 INFO  MeanRegressor   - Validation - Epoch 1: Loss: 283.859 RMSE: 16.821\n",
      "2020-01-13 14:48:06,513 INFO  MeanRegressor   - Train - Epoch 2: Loss: 163.417 RMSE: 12.657\n",
      "2020-01-13 14:48:06,516 INFO  MeanRegressor   - Validation - Epoch 2: Loss: 34.268 RMSE: 5.846\n",
      "2020-01-13 14:48:06,534 INFO  MeanRegressor   - Train - Epoch 3: Loss: 126.636 RMSE: 11.013\n",
      "2020-01-13 14:48:06,536 INFO  MeanRegressor   - Validation - Epoch 3: Loss: 61.126 RMSE: 7.783\n",
      "2020-01-13 14:48:06,555 INFO  MeanRegressor   - Train - Epoch 4: Loss: 87.824 RMSE: 9.250\n",
      "2020-01-13 14:48:06,558 INFO  MeanRegressor   - Validation - Epoch 4: Loss: 58.893 RMSE: 7.674\n",
      "2020-01-13 14:48:06,579 INFO  MeanRegressor   - Train - Epoch 5: Loss: 74.737 RMSE: 8.451\n",
      "2020-01-13 14:48:06,580 INFO  MeanRegressor   - Validation - Epoch 5: Loss: 28.216 RMSE: 5.299\n",
      "2020-01-13 14:48:06,606 INFO  MeanRegressor   - Train - Epoch 6: Loss: 72.343 RMSE: 8.374\n",
      "2020-01-13 14:48:06,609 INFO  MeanRegressor   - Validation - Epoch 6: Loss: 24.108 RMSE: 4.810\n",
      "2020-01-13 14:48:06,633 INFO  MeanRegressor   - Train - Epoch 7: Loss: 69.493 RMSE: 8.199\n",
      "2020-01-13 14:48:06,635 INFO  MeanRegressor   - Validation - Epoch 7: Loss: 23.768 RMSE: 4.819\n",
      "2020-01-13 14:48:06,654 INFO  MeanRegressor   - Train - Epoch 8: Loss: 68.126 RMSE: 8.131\n",
      "2020-01-13 14:48:06,656 INFO  MeanRegressor   - Validation - Epoch 8: Loss: 22.849 RMSE: 4.774\n",
      "2020-01-13 14:48:06,675 INFO  MeanRegressor   - Train - Epoch 9: Loss: 66.923 RMSE: 8.034\n",
      "2020-01-13 14:48:06,677 INFO  MeanRegressor   - Validation - Epoch 9: Loss: 23.478 RMSE: 4.844\n",
      "2020-01-13 14:48:06,699 INFO  MeanRegressor   - Train - Epoch 10: Loss: 65.867 RMSE: 7.968\n",
      "2020-01-13 14:48:06,702 INFO  MeanRegressor   - Validation - Epoch 10: Loss: 20.259 RMSE: 4.422\n",
      "2020-01-13 14:48:06,722 INFO  MeanRegressor   - Train - Epoch 11: Loss: 68.514 RMSE: 8.135\n",
      "2020-01-13 14:48:06,724 INFO  MeanRegressor   - Validation - Epoch 11: Loss: 26.459 RMSE: 5.053\n",
      "2020-01-13 14:48:06,743 INFO  MeanRegressor   - Train - Epoch 12: Loss: 65.875 RMSE: 8.045\n",
      "2020-01-13 14:48:06,745 INFO  MeanRegressor   - Validation - Epoch 12: Loss: 21.694 RMSE: 4.604\n",
      "2020-01-13 14:48:06,763 INFO  MeanRegressor   - Train - Epoch 13: Loss: 62.919 RMSE: 7.823\n",
      "2020-01-13 14:48:06,764 INFO  MeanRegressor   - Validation - Epoch 13: Loss: 23.427 RMSE: 4.809\n",
      "2020-01-13 14:48:06,785 INFO  MeanRegressor   - Train - Epoch 14: Loss: 67.319 RMSE: 8.084\n",
      "2020-01-13 14:48:06,787 INFO  MeanRegressor   - Validation - Epoch 14: Loss: 20.850 RMSE: 4.165\n",
      "2020-01-13 14:48:06,806 INFO  MeanRegressor   - Train - Epoch 15: Loss: 62.519 RMSE: 7.787\n",
      "2020-01-13 14:48:06,809 INFO  MeanRegressor   - Validation - Epoch 15: Loss: 22.368 RMSE: 4.726\n",
      "2020-01-13 14:48:06,830 INFO  MeanRegressor   - Train - Epoch 16: Loss: 60.098 RMSE: 7.586\n",
      "2020-01-13 14:48:06,832 INFO  MeanRegressor   - Validation - Epoch 16: Loss: 24.932 RMSE: 4.988\n",
      "2020-01-13 14:48:06,853 INFO  MeanRegressor   - Train - Epoch 17: Loss: 57.639 RMSE: 7.374\n",
      "2020-01-13 14:48:06,855 INFO  MeanRegressor   - Validation - Epoch 17: Loss: 22.790 RMSE: 4.772\n",
      "2020-01-13 14:48:06,878 INFO  MeanRegressor   - Train - Epoch 18: Loss: 57.560 RMSE: 7.421\n",
      "2020-01-13 14:48:06,880 INFO  MeanRegressor   - Validation - Epoch 18: Loss: 23.100 RMSE: 4.804\n",
      "2020-01-13 14:48:06,903 INFO  MeanRegressor   - Train - Epoch 19: Loss: 59.425 RMSE: 7.586\n",
      "2020-01-13 14:48:06,906 INFO  MeanRegressor   - Validation - Epoch 19: Loss: 24.706 RMSE: 4.954\n",
      "2020-01-13 14:48:06,928 INFO  MeanRegressor   - Train - Epoch 20: Loss: 61.126 RMSE: 7.607\n",
      "2020-01-13 14:48:06,930 INFO  MeanRegressor   - Validation - Epoch 20: Loss: 24.744 RMSE: 4.881\n",
      "2020-01-13 14:48:06,953 INFO  MeanRegressor   - Train - Epoch 21: Loss: 60.705 RMSE: 7.553\n",
      "2020-01-13 14:48:06,955 INFO  MeanRegressor   - Validation - Epoch 21: Loss: 22.117 RMSE: 4.653\n",
      "2020-01-13 14:48:06,978 INFO  MeanRegressor   - Train - Epoch 22: Loss: 53.257 RMSE: 7.086\n",
      "2020-01-13 14:48:06,980 INFO  MeanRegressor   - Validation - Epoch 22: Loss: 20.941 RMSE: 4.435\n",
      "2020-01-13 14:48:07,004 INFO  MeanRegressor   - Train - Epoch 23: Loss: 54.002 RMSE: 7.093\n",
      "2020-01-13 14:48:07,006 INFO  MeanRegressor   - Validation - Epoch 23: Loss: 21.730 RMSE: 4.525\n",
      "2020-01-13 14:48:07,028 INFO  MeanRegressor   - Train - Epoch 24: Loss: 57.702 RMSE: 7.434\n",
      "2020-01-13 14:48:07,030 INFO  MeanRegressor   - Validation - Epoch 24: Loss: 23.087 RMSE: 4.805\n",
      "2020-01-13 14:48:07,048 INFO  MeanRegressor   - Train - Epoch 25: Loss: 51.893 RMSE: 7.014\n",
      "2020-01-13 14:48:07,050 INFO  MeanRegressor   - Validation - Epoch 25: Loss: 35.098 RMSE: 5.607\n",
      "2020-01-13 14:48:07,071 INFO  MeanRegressor   - Train - Epoch 26: Loss: 52.053 RMSE: 7.126\n",
      "2020-01-13 14:48:07,073 INFO  MeanRegressor   - Validation - Epoch 26: Loss: 23.886 RMSE: 4.842\n",
      "2020-01-13 14:48:07,093 INFO  MeanRegressor   - Train - Epoch 27: Loss: 50.675 RMSE: 6.908\n",
      "2020-01-13 14:48:07,095 INFO  MeanRegressor   - Validation - Epoch 27: Loss: 26.426 RMSE: 5.085\n",
      "2020-01-13 14:48:07,113 INFO  MeanRegressor   - Train - Epoch 28: Loss: 48.632 RMSE: 6.741\n",
      "2020-01-13 14:48:07,115 INFO  MeanRegressor   - Validation - Epoch 28: Loss: 25.972 RMSE: 5.010\n",
      "2020-01-13 14:48:07,135 INFO  MeanRegressor   - Train - Epoch 29: Loss: 48.827 RMSE: 6.844\n",
      "2020-01-13 14:48:07,137 INFO  MeanRegressor   - Validation - Epoch 29: Loss: 26.297 RMSE: 5.127\n",
      "2020-01-13 14:48:07,159 INFO  MeanRegressor   - Train - Epoch 30: Loss: 49.840 RMSE: 6.951\n",
      "2020-01-13 14:48:07,162 INFO  MeanRegressor   - Validation - Epoch 30: Loss: 26.175 RMSE: 5.069\n",
      "2020-01-13 14:48:07,190 INFO  MeanRegressor   - Train - Epoch 31: Loss: 47.149 RMSE: 6.756\n",
      "2020-01-13 14:48:07,192 INFO  MeanRegressor   - Validation - Epoch 31: Loss: 24.218 RMSE: 4.914\n",
      "2020-01-13 14:48:07,217 INFO  MeanRegressor   - Train - Epoch 32: Loss: 48.059 RMSE: 6.826\n",
      "2020-01-13 14:48:07,221 INFO  MeanRegressor   - Validation - Epoch 32: Loss: 22.662 RMSE: 4.760\n",
      "2020-01-13 14:48:07,245 INFO  MeanRegressor   - Train - Epoch 33: Loss: 47.185 RMSE: 6.759\n",
      "2020-01-13 14:48:07,247 INFO  MeanRegressor   - Validation - Epoch 33: Loss: 30.989 RMSE: 5.474\n",
      "2020-01-13 14:48:07,270 INFO  MeanRegressor   - Train - Epoch 34: Loss: 48.262 RMSE: 6.838\n",
      "2020-01-13 14:48:07,273 INFO  MeanRegressor   - Validation - Epoch 34: Loss: 24.760 RMSE: 4.976\n",
      "2020-01-13 14:48:07,299 INFO  MeanRegressor   - Train - Epoch 35: Loss: 45.405 RMSE: 6.505\n",
      "2020-01-13 14:48:07,301 INFO  MeanRegressor   - Validation - Epoch 35: Loss: 23.982 RMSE: 4.778\n",
      "2020-01-13 14:48:07,322 INFO  MeanRegressor   - Train - Epoch 36: Loss: 44.155 RMSE: 6.349\n",
      "2020-01-13 14:48:07,326 INFO  MeanRegressor   - Validation - Epoch 36: Loss: 24.482 RMSE: 4.897\n",
      "2020-01-13 14:48:07,347 INFO  MeanRegressor   - Train - Epoch 37: Loss: 43.855 RMSE: 6.407\n",
      "2020-01-13 14:48:07,350 INFO  MeanRegressor   - Validation - Epoch 37: Loss: 25.195 RMSE: 5.018\n",
      "2020-01-13 14:48:07,369 INFO  MeanRegressor   - Train - Epoch 38: Loss: 45.987 RMSE: 6.658\n",
      "2020-01-13 14:48:07,371 INFO  MeanRegressor   - Validation - Epoch 38: Loss: 23.865 RMSE: 4.850\n",
      "2020-01-13 14:48:07,393 INFO  MeanRegressor   - Train - Epoch 39: Loss: 47.377 RMSE: 6.708\n",
      "2020-01-13 14:48:07,395 INFO  MeanRegressor   - Validation - Epoch 39: Loss: 20.346 RMSE: 4.292\n",
      "2020-01-13 14:48:07,417 INFO  MeanRegressor   - Train - Epoch 40: Loss: 42.507 RMSE: 6.431\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 14:48:07,420 INFO  MeanRegressor   - Validation - Epoch 40: Loss: 26.030 RMSE: 4.944\n"
     ]
    }
   ],
   "source": [
    "log_file = Path(\"{}_{}.log\".format(\n",
    "    EXPERIMENT_NAME,\n",
    "    datetime.now().strftime(\"%Y%m%d_%H%M%S\")))\n",
    "utils.setup_logger(log_path=Path.cwd() / args.log_dir / log_file,\n",
    "                   log_level=args.log_level)\n",
    "LOGGER.info(\"Args: {}\".format(args))\n",
    "device = utils.torch_settings(args.seed, args.gpu)\n",
    "LOGGER.info(\"Creating dataloader\")\n",
    "training_data, validation_data = uci_bost.BostonData(\n",
    "    \"~/doktor/datasets/UCI/bost/housing.data\").create_train_val_split(\n",
    "    training_samples_ratio=0.9)\n",
    "\n",
    "input_size = 13\n",
    "layer_sizes = [input_size, 50, 1]\n",
    "ensemble_output_size = layer_sizes[-1] * 2\n",
    "args.num_ensemble_members = 1\n",
    "args.num_epochs=40\n",
    "args.lr = 0.001\n",
    "args.log_level = logging.INFO\n",
    "train_loader = torch.utils.data.DataLoader(training_data,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data,\n",
    "                                                batch_size=32,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0)\n",
    "\n",
    "prob_ensemble = ensemble.Ensemble(ensemble_output_size)\n",
    "for _ in range(args.num_ensemble_members):\n",
    "    model = mean_regressor.MeanRegressor(layer_sizes,\n",
    "                                       device=device,\n",
    "                                       learning_rate=args.lr)\n",
    "    prob_ensemble.add_member(model)\n",
    "squared_error_metric = metrics.Metric(name=\"RMSE\",\n",
    "                                      function=metrics.root_mean_squared_error)\n",
    "prob_ensemble.add_metrics([squared_error_metric])\n",
    "\n",
    "prob_ensemble.train(train_loader, args.num_epochs, validation_loader=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(20.4444)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_data, validation_data = uci_bost.BostonData(\n",
    "    \"~/doktor/datasets/UCI/bost/housing.data\").create_train_val_split(\n",
    "    training_samples_ratio=0.9)\n",
    "model = prob_ensemble.members[0]\n",
    "test_x, test_y = validation_data[0]\n",
    "\n",
    "model._validate_epoch(validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[74.8908,  0.0000]], grad_fn=<CopySlices>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-01-13 14:30:53,757 INFO  root            - Log at /home/jakob/doktor/projects/EnsembleUncertainty/code/logs/regression_logits_20200113_143053.log\n",
      "2020-01-13 14:30:53,758 INFO  __main__        - Args: <__main__.Args object at 0x7f3705a64588>\n",
      "2020-01-13 14:30:53,759 INFO  __main__        - Creating dataloader\n",
      "2020-01-13 14:30:53,765 INFO  SepRegressor    - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,765 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,766 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,767 WARNING Ensemble        - Is subclass check disabled\n",
      "2020-01-13 14:30:53,768 INFO  Ensemble        - Adding <class 'src.ensemble.sep_regressor.SepRegressor'> to ensemble\n",
      "2020-01-13 14:30:53,768 INFO  SepRegressor    - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,768 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,770 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,770 WARNING Ensemble        - Is subclass check disabled\n",
      "2020-01-13 14:30:53,771 INFO  Ensemble        - Adding <class 'src.ensemble.sep_regressor.SepRegressor'> to ensemble\n",
      "2020-01-13 14:30:53,771 INFO  SepRegressor    - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,772 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,773 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,773 WARNING Ensemble        - Is subclass check disabled\n",
      "2020-01-13 14:30:53,774 INFO  Ensemble        - Adding <class 'src.ensemble.sep_regressor.SepRegressor'> to ensemble\n",
      "2020-01-13 14:30:53,775 INFO  SepRegressor    - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,776 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,777 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,779 WARNING Ensemble        - Is subclass check disabled\n",
      "2020-01-13 14:30:53,780 INFO  Ensemble        - Adding <class 'src.ensemble.sep_regressor.SepRegressor'> to ensemble\n",
      "2020-01-13 14:30:53,780 INFO  SepRegressor    - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,781 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,783 INFO  MeanRegressor   - Moving model to device: cpu\n",
      "2020-01-13 14:30:53,784 WARNING Ensemble        - Is subclass check disabled\n",
      "2020-01-13 14:30:53,785 INFO  Ensemble        - Adding <class 'src.ensemble.sep_regressor.SepRegressor'> to ensemble\n",
      "2020-01-13 14:30:53,786 INFO  Ensemble        - Adding metric: Squared error\n",
      "2020-01-13 14:30:53,786 INFO  Ensemble        - Adding metric: Squared error\n",
      "2020-01-13 14:30:53,786 INFO  Ensemble        - Adding metric: Squared error\n",
      "2020-01-13 14:30:53,787 INFO  Ensemble        - Adding metric: Squared error\n",
      "2020-01-13 14:30:53,788 INFO  Ensemble        - Adding metric: Squared error\n",
      "2020-01-13 14:30:53,789 INFO  Ensemble        - Training ensemble\n",
      "2020-01-13 14:30:53,789 INFO  Ensemble        - Training member 1/5\n",
      "2020-01-13 14:30:53,790 WARNING src.metrics     - Trying to calculate mean on unpopulated metric.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cholesky_cpu: U(1,1) is zero, singular U.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-9edd64590c9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mmember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean_only\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 42\u001b[0;31m \u001b[0mprob_ensemble\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/doktor/projects/EnsembleUncertainty/code/src/ensemble/ensemble.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, num_epochs, validation_loader)\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmember\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmembers\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_log\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Training member {}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mind\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m             \u001b[0mmember\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd_metrics\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/doktor/projects/EnsembleUncertainty/code/src/ensemble/ensemble.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, train_loader, num_epochs, validation_loader)\u001b[0m\n\u001b[1;32m    206\u001b[0m                                                     gamma=0.1)\n\u001b[1;32m    207\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mepoch_number\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 208\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_train_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    209\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_print_epoch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch_number\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Train\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mvalidation_loader\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/doktor/projects/EnsembleUncertainty/code/src/ensemble/ensemble.py\u001b[0m in \u001b[0;36m_train_epoch\u001b[0;34m(self, train_loader, validation_loader)\u001b[0m\n\u001b[1;32m    243\u001b[0m                 (batch_size, num_samples, self.target_size))\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcalculate_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/doktor/projects/EnsembleUncertainty/code/src/ensemble/sep_regressor.py\u001b[0m in \u001b[0;36mcalculate_loss\u001b[0;34m(self, outputs, targets)\u001b[0m\n\u001b[1;32m     71\u001b[0m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcustom_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 73\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     74\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/doktor/projects/EnsembleUncertainty/code/src/loss.py\u001b[0m in \u001b[0;36mgaussian_neg_log_likelihood\u001b[0;34m(parameters, target)\u001b[0m\n\u001b[1;32m     81\u001b[0m         \u001b[0mcov_mat_b\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcov_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdiag\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mdistr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_mvn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMultivariateNormal\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmean_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcov_mat_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0mlog_prob\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdistr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog_prob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/doktor/projects/EnsembleUncertainty/code/venv/lib/python3.6/site-packages/torch/distributions/multivariate_normal.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, loc, covariance_matrix, precision_matrix, scale_tril, validate_args)\u001b[0m\n\u001b[1;32m    147\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mscale_tril\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    148\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mcovariance_matrix\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcholesky\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcovariance_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    150\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# precision_matrix is not None\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_unbroadcasted_scale_tril\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_precision_to_scale_tril\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprecision_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cholesky_cpu: U(1,1) is zero, singular U."
     ]
    }
   ],
   "source": [
    "log_file = Path(\"{}_{}.log\".format(\n",
    "    EXPERIMENT_NAME,\n",
    "    datetime.now().strftime(\"%Y%m%d_%H%M%S\")))\n",
    "utils.setup_logger(log_path=Path.cwd() / args.log_dir / log_file,\n",
    "                   log_level=args.log_level)\n",
    "LOGGER.info(\"Args: {}\".format(args))\n",
    "device = utils.torch_settings(args.seed, args.gpu)\n",
    "LOGGER.info(\"Creating dataloader\")\n",
    "training_data, validation_data = uci_bost.BostonData(\n",
    "    \"~/doktor/datasets/UCI/bost/housing.data\").create_train_val_split(\n",
    "    training_samples_ratio=0.9)\n",
    "\n",
    "input_size = 13\n",
    "layer_sizes = [input_size, 50, 1]\n",
    "ensemble_output_size = layer_sizes[-1] * 2\n",
    "args.num_ensemble_members = 5\n",
    "args.num_epochs=40\n",
    "args.lr = 0.00001\n",
    "args.log_level = logging.DEBUG\n",
    "train_loader = torch.utils.data.DataLoader(training_data,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "\n",
    "prob_ensemble = ensemble.Ensemble(ensemble_output_size)\n",
    "for _ in range(args.num_ensemble_members):\n",
    "    model = sep_regressor.SepRegressor(layer_sizes,\n",
    "                                       device=device,\n",
    "                                       learning_rate=args.lr)\n",
    "    prob_ensemble.add_member(model)\n",
    "squared_error_metric = metrics.Metric(name=\"Squared error\",\n",
    "                                      function=metrics.mean_squared_error)\n",
    "prob_ensemble.add_metrics([squared_error_metric])\n",
    "for member in prob_ensemble.members:\n",
    "        member.mean_only = False\n",
    "        \n",
    "prob_ensemble.train(train_loader, args.num_epochs, validation_loader=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_ensemble.members[0]._validate_epoch(validation_loader=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_file = Path(\"{}_{}.log\".format(\n",
    "    EXPERIMENT_NAME,\n",
    "    datetime.now().strftime(\"%Y%m%d_%H%M%S\")))\n",
    "utils.setup_logger(log_path=Path.cwd() / args.log_dir / log_file,\n",
    "                   log_level=args.log_level)\n",
    "LOGGER.info(\"Args: {}\".format(args))\n",
    "device = utils.torch_settings(args.seed, args.gpu)\n",
    "LOGGER.info(\"Creating dataloader\")\n",
    "training_data, validation_data = uci_bost.BostonData(\n",
    "    \"~/doktor/datasets/UCI/bost/housing.data\").create_train_val_split(\n",
    "    training_samples_ratio=0.9)\n",
    "\n",
    "input_size = 13\n",
    "layer_sizes = [input_size, 50, 2]\n",
    "ensemble_output_size = layer_sizes[-1]\n",
    "args.num_ensemble_members = 1\n",
    "args.num_epochs=40\n",
    "args.lr = 0.001\n",
    "args.log_level = logging.DEBUG\n",
    "train_loader = torch.utils.data.DataLoader(training_data,\n",
    "                                           batch_size=32,\n",
    "                                           shuffle=True,\n",
    "                                           num_workers=0)\n",
    "validation_loader = torch.utils.data.DataLoader(validation_data,\n",
    "                                                batch_size=32,\n",
    "                                                shuffle=True,\n",
    "                                                num_workers=0)\n",
    "\n",
    "prob_ensemble = ensemble.Ensemble(ensemble_output_size)\n",
    "for _ in range(args.num_ensemble_members):\n",
    "    model = simple_regressor.SimpleRegressor(layer_sizes,\n",
    "                                       device=device,\n",
    "                                       learning_rate=args.lr)\n",
    "    model.mean_only = True\n",
    "    prob_ensemble.add_member(model)\n",
    "squared_error_metric = metrics.Metric(name=\"Squared error\",\n",
    "                                      function=metrics.mean_squared_error)\n",
    "prob_ensemble.add_metrics([squared_error_metric])\n",
    "prob_ensemble.train(train_loader, args.num_epochs, validation_loader=validation_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for member in prob_ensemble.members:\n",
    "        member.mean_only = False\n",
    "prob_ensemble.train(train_loader, args.num_epochs, validation_loader=validation_loader)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
