{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10811,
     "status": "ok",
     "timestamp": 1558128143256,
     "user": {
      "displayName": "Stratis Markou",
      "photoUrl": "",
      "userId": "09754366312766083286"
     },
     "user_tz": -60
    },
    "id": "xAYPKSFrG8AF",
    "outputId": "cf3df00b-2fcc-48ba-bd75-af624f50aa20"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/jakob/doktor/projects/EnsembleUncertainty/code\")\n",
    "\"\"\"Learing \"logit\" distribution in regression example\"\"\"\n",
    "import logging\n",
    "import zipfile\n",
    "from copy import copy, deepcopy\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.sgd import SGD\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.model_selection import KFold\n",
    "from src.dataloaders.uci import uci_base, wine, bost\n",
    "from src import metrics\n",
    "from src import utils\n",
    "from src.ensemble import simple_regressor, ensemble\n",
    "from src import loss as custom_loss\n",
    "\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "EXPERIMENT_NAME = \"red_regression_logits\"\n",
    "\n",
    "# Settings\n",
    "class Args():\n",
    "    pass\n",
    "args = Args()\n",
    "args.seed = 1\n",
    "args.gpu = False\n",
    "args.log_dir = Path(\"./logs\")\n",
    "args.log_level = logging.INFO\n",
    "args.retrain = True\n",
    "\n",
    "args.num_ensemble_members=1\n",
    "args.num_epochs=1\n",
    "args.lr = 0.01\n",
    "\n",
    "# General constructs\n",
    "test_metrics = list()\n",
    "mse = metrics.Metric(name=\"MSE\", function=metrics.mean_squared_error)\n",
    "#test_metrics.append(mse)\n",
    "rmse = metrics.Metric(name=\"RMSE\", function=metrics.root_mean_squared_error)\n",
    "test_metrics.append(rmse)\n",
    "\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "device = torch.device(\"cuda\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1S5kt0omQ-N"
   },
   "outputs": [],
   "source": [
    "def to_variable(var=(), cuda=True, volatile=False):\n",
    "    out = []\n",
    "    for v in var:\n",
    "        \n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = torch.from_numpy(v).type(torch.FloatTensor)\n",
    "\n",
    "        if not v.is_cuda and cuda:\n",
    "            v = v.cuda()\n",
    "\n",
    "        if not isinstance(v, Variable):\n",
    "            v = Variable(v, volatile=volatile)\n",
    "\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "def get_loss_and_rmse(network,\n",
    "                      loss_function,\n",
    "                      x, y,\n",
    "                      mean_shift=None, std_scale=None):\n",
    "    x, y = to_variable(var=(x, y), cuda=True)\n",
    "\n",
    "    logits = network.forward(x)\n",
    "    output = network.transform_logits(logits)\n",
    "    mean, std = output\n",
    "\n",
    "    if mean_shift is not None and std_scale is not None:\n",
    "        mean_shift = torch.tensor(mean_shift).float().cuda()\n",
    "        std_scale = torch.tensor(std_scale).float().cuda()\n",
    "        mean = mean * std_scale + mean_shift\n",
    "        y = y * std_scale + mean_shift\n",
    "        std *= std_scale\n",
    "\n",
    "    loss = loss_function((mean, std), y)\n",
    "\n",
    "    rmse = ((mean - y)**2).mean()**0.5\n",
    "\n",
    "    return loss.detach().cpu(), rmse.detach().cpu()\n",
    "\n",
    "def create_ensemble(num_ensemble_members,\n",
    "                    model,\n",
    "                    ensemble_output_size):\n",
    "    prob_ensemble = ensemble.Ensemble(ensemble_output_size)\n",
    "    for _ in range(num_ensemble_members):\n",
    "        prob_ensemble.add_member(copy(model))\n",
    "    return prob_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QBBlvk1JylkX"
   },
   "source": [
    "# UCI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AmcpT5DDO2d"
   },
   "outputs": [],
   "source": [
    "def train_mc_dropout(data,\n",
    "                     drop_prob,\n",
    "                     n_splits,\n",
    "                     num_epochs,\n",
    "                     num_units,\n",
    "                     learn_rate,\n",
    "                     weight_decay,\n",
    "                     metrics,\n",
    "                     batch_size):\n",
    "    \n",
    "    kf = KFold(n_splits=n_splits)\n",
    "    in_dim = data.shape[1] - 1\n",
    "    train_nll, test_nll = [], []\n",
    "    train_rmses, test_rmses = [], []\n",
    "    for metric in metrics:\n",
    "        metric.reset()\n",
    "        \n",
    "\n",
    "    network = simple_regressor.Model(layer_sizes=[in_dim, num_units, 2],\n",
    "                                     device=device,\n",
    "                                     variance_transform=utils.variance_linear_asymptote(),\n",
    "                                     loss_function=custom_loss.gaussian_neg_log_likelihood_1d)\n",
    "\n",
    "    network.optimizer = torch.optim.SGD(network.parameters(),\n",
    "                                lr=learn_rate,\n",
    "                                weight_decay=weight_decay)\n",
    "    prob_ensemble = create_ensemble(num_ensemble_members=args.num_ensemble_members,\n",
    "                               model=network,\n",
    "                               ensemble_output_size=1)\n",
    "\n",
    "    prob_ensemble.add_metrics(test_metrics)\n",
    "\n",
    "        \n",
    "    for fold_count, idx in enumerate(kf.split(data)):\n",
    "        print(\"Fold: {}\".format(fold_count))\n",
    "        train_index, test_index = idx\n",
    "        x_train, y_train = data[train_index, :in_dim], data[train_index, in_dim:]\n",
    "        x_test, y_test = data[test_index, :in_dim], data[test_index, in_dim:]\n",
    "\n",
    "        x_means, x_stds = x_train.mean(axis = 0), x_train.var(axis = 0)**0.5\n",
    "        y_means, y_stds = y_train.mean(axis = 0), y_train.var(axis = 0)**0.5\n",
    "\n",
    "        x_train = (x_train - x_means) / x_stds\n",
    "        y_train = (y_train - y_means) / y_stds\n",
    "\n",
    "        x_test = (x_test - x_means) / x_stds\n",
    "        y_test = (y_test - y_means) / y_stds\n",
    "                \n",
    "        trainloader = uci_base.uci_dataloader(x_train, y_train, batch_size)\n",
    "        \n",
    "        losses = []\n",
    "        prob_ensemble.train(train_loader=trainloader,\n",
    "                            num_epochs=num_epochs)\n",
    "    \n",
    "        \n",
    "        mean_shift = None\n",
    "        std_scale = None\n",
    "        #mean_shift = y_means\n",
    "        #std_scale = y_stds\n",
    "        \n",
    "        train_loss, train_rmse = get_loss_and_rmse(network,\n",
    "                                                   network.loss,\n",
    "                                                   x_train,\n",
    "                                                   y_train,\n",
    "                                                   mean_shift=mean_shift,\n",
    "                                                   std_scale=std_scale)\n",
    "        \n",
    "        test_loss, test_rmse = get_loss_and_rmse(network,\n",
    "                                                 network.loss,\n",
    "                                                 x_test,\n",
    "                                                 y_test,\n",
    "                                                 mean_shift=mean_shift,\n",
    "                                                 std_scale=std_scale)\n",
    "        \n",
    "        testloader = uci_base.uci_dataloader(x_test, y_test, len(y_test))\n",
    "        \n",
    "        metrics, test_loss = network.test(testloader, metrics, network.loss)\n",
    "        train_nll.append((train_loss.cpu().data.numpy()/len(x_train) + np.log(y_stds)[0]))\n",
    "        test_nll.append((test_loss.cpu().data.numpy()/len(x_test) + np.log(y_stds)[0]))\n",
    "\n",
    "        train_rmses.append(y_stds[0]*train_rmse.cpu().data.numpy())\n",
    "        test_rmses.append(y_stds[0]*test_rmse.cpu().data.numpy())\n",
    "        \n",
    "        fold_metric = metrics[0].memory[-1]\n",
    "        print(\"Train loss: {:.3f} Test loss: {:.3f} RMSE: {:.3f}\".format(\n",
    "            train_loss/len(x_train),\n",
    "            test_loss/len(x_test),\n",
    "            y_stds[0]* fold_metric))\n",
    "\n",
    "    my_rmse_mean, my_rmse_std = y_stds[0] * metrics[0].mean(), y_stds[0] * metrics[0].std()\n",
    "    print(\"Train NLL\\t = {:.3f} +/- {:.3f}\".format(np.array(train_nll).mean(),\n",
    "                                                   np.array(train_nll).var()**0.5))\n",
    "    print(\"Test  NLL\\t = {:.3f} +/- {:.3f}\".format(np.array(test_nll).mean(),\n",
    "                                                   np.array(test_nll).var()**0.5))\n",
    "    print(\"Train RMSE\\t = {:.3f} +/- {:.3f}\".format(np.array(train_rmses).mean(),\n",
    "                                                    np.array(train_rmses).var()**0.5))\n",
    "    print(\"Test RMSE\\t = {:.3f} +/- {:.3f}\".format(np.array(test_rmses).mean(),\n",
    "                                                   np.array(test_rmses).var()**0.5))\n",
    "    print(\"My RMSE\\t = {:.3f} +/- {:.3f}\".format(my_rmse_mean, my_rmse_std))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRPICBiXCegI"
   },
   "source": [
    "# Red wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4542,
     "status": "ok",
     "timestamp": 1558130529014,
     "user": {
      "displayName": "Stratis Markou",
      "photoUrl": "",
      "userId": "09754366312766083286"
     },
     "user_tz": -60
    },
    "id": "KOqgIBXcCegJ",
    "outputId": "21e7e896-5a30-4692-ff6d-72182f4b83b4"
   },
   "outputs": [],
   "source": [
    "wine_data = wine.WineData(\"data/uci/wine/winequality-red.csv\").data\n",
    "train_mc_dropout(data=wine_data,\n",
    "                       drop_prob=0.0,\n",
    "                       num_epochs=40,\n",
    "                       n_splits=10,\n",
    "                       num_units=50,\n",
    "                       learn_rate=1e-4,\n",
    "                       weight_decay=0.0, #1e-1/len(data)**0.5,\n",
    "                       metrics=test_metrics,\n",
    "                       batch_size=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CA4b-sP4eBJw"
   },
   "source": [
    "# Housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 204
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4105,
     "status": "ok",
     "timestamp": 1558130357708,
     "user": {
      "displayName": "Stratis Markou",
      "photoUrl": "",
      "userId": "09754366312766083286"
     },
     "user_tz": -60
    },
    "id": "OHCuHqooeBJy",
    "outputId": "3f074919-5888-44fb-f31f-8aebe18e000b"
   },
   "outputs": [],
   "source": [
    "bost_data = bost.BostonData(\"data/uci/bost/housing.data\").data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5232,
     "status": "ok",
     "timestamp": 1558130359147,
     "user": {
      "displayName": "Stratis Markou",
      "photoUrl": "",
      "userId": "09754366312766083286"
     },
     "user_tz": -60
    },
    "id": "UXsgiUziqh9w",
    "outputId": "0b125922-91ea-4c97-904b-c6c6197e2a80"
   },
   "outputs": [],
   "source": [
    "net = train_mc_dropout(data=bost_data,\n",
    "                       drop_prob=0.0,\n",
    "                       num_epochs=40,\n",
    "                       n_splits=10,\n",
    "                       num_units=50,\n",
    "                       learn_rate=1e-4,\n",
    "                       weight_decay=0.0, #1e-1/len(data)**0.5,\n",
    "                       num_samples=20,\n",
    "                       log_every=50,\n",
    "                       batch_size=1411)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mc_dropout_heteroscedastic.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
