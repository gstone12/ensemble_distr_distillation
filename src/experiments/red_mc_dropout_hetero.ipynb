{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10811,
     "status": "ok",
     "timestamp": 1558128143256,
     "user": {
      "displayName": "Stratis Markou",
      "photoUrl": "",
      "userId": "09754366312766083286"
     },
     "user_tz": -60
    },
    "id": "xAYPKSFrG8AF",
    "outputId": "cf3df00b-2fcc-48ba-bd75-af624f50aa20"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-12 09:09:48,318 INFO  root            - Log at /home/jakob/doktor/projects/EnsembleUncertainty/code/logs/red_regression_logits_20200212_090948.log\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.chdir(\"/home/jakob/doktor/projects/EnsembleUncertainty/code\")\n",
    "\"\"\"Learing \"logit\" distribution in regression example\"\"\"\n",
    "import logging\n",
    "import zipfile\n",
    "from copy import copy, deepcopy\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.sgd import SGD\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.model_selection import KFold\n",
    "from src.dataloaders.uci import uci_base, wine, bost\n",
    "from src import metrics\n",
    "from src import utils\n",
    "from src.ensemble import simple_regressor, ensemble\n",
    "from src import loss as custom_loss\n",
    "\n",
    "# Settings\n",
    "class Args():\n",
    "    pass\n",
    "args = Args()\n",
    "args.seed = 1\n",
    "args.gpu = False\n",
    "args.log_dir = Path(\"./logs\")\n",
    "args.log_level = logging.INFO\n",
    "args.retrain = True\n",
    "args.num_ensemble_members=1\n",
    "args.num_epochs=1\n",
    "args.lr = 0.01\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "EXPERIMENT_NAME = \"red_regression_logits\"\n",
    "\n",
    "log_file = Path(\"{}_{}.log\".format(\n",
    "    EXPERIMENT_NAME,\n",
    "    datetime.now().strftime(\"%Y%m%d_%H%M%S\")))\n",
    "utils.setup_logger(log_path=Path.cwd() / args.log_dir / log_file,\n",
    "                   log_level=args.log_level)\n",
    "\n",
    "# General constructs\n",
    "train_metrics = list()\n",
    "test_metrics = list()\n",
    "\n",
    "rmse = metrics.Metric(name=\"RMSE\", function=metrics.root_mean_squared_error)\n",
    "train_metrics.append(deepcopy(rmse))\n",
    "test_metrics.append(rmse)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "device = torch.device(\"cuda\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1S5kt0omQ-N"
   },
   "outputs": [],
   "source": [
    "def to_variable(var=(), cuda=True, volatile=False):\n",
    "    out = []\n",
    "    for v in var:\n",
    "        \n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = torch.from_numpy(v).type(torch.FloatTensor)\n",
    "\n",
    "        if not v.is_cuda and cuda:\n",
    "            v = v.cuda()\n",
    "\n",
    "        if not isinstance(v, Variable):\n",
    "            v = Variable(v, volatile=volatile)\n",
    "\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "def get_loss_and_rmse(network,\n",
    "                      loss_function,\n",
    "                      x, y,\n",
    "                      mean_shift=None, std_scale=None):\n",
    "    x, y = to_variable(var=(x, y), cuda=True)\n",
    "\n",
    "    logits = network.forward(x)\n",
    "    output = network.transform_logits(logits)\n",
    "    mean, std = output\n",
    "\n",
    "    if mean_shift is not None and std_scale is not None:\n",
    "        mean_shift = torch.tensor(mean_shift).float().cuda()\n",
    "        std_scale = torch.tensor(std_scale).float().cuda()\n",
    "        mean = mean * std_scale + mean_shift\n",
    "        y = y * std_scale + mean_shift\n",
    "        std *= std_scale\n",
    "\n",
    "    loss = loss_function((mean, std), y)\n",
    "\n",
    "    rmse = ((mean - y)**2).mean()**0.5\n",
    "\n",
    "    return loss.detach().cpu(), rmse.detach().cpu()\n",
    "\n",
    "def create_ensemble(num_ensemble_members,\n",
    "                    model,\n",
    "                    ensemble_output_size):\n",
    "    prob_ensemble = ensemble.Ensemble(ensemble_output_size)\n",
    "    for _ in range(num_ensemble_members):\n",
    "        prob_ensemble.add_member(copy(model))\n",
    "    return prob_ensemble\n",
    "\n",
    "def mean_and_std_from_list(samples):\n",
    "    \"\"\"Calculate mean and std from np-array compatible list\"\"\"\n",
    "    array = np.array(samples)\n",
    "    return array.mean(), array.std()\n",
    "\n",
    "def mean_and_std_from_metric(metric, rescale=1):\n",
    "    \"\"\"Calculate mean and std from np-array compatible list\"\"\"\n",
    "    return metric.mean() * rescale, metric.std() * rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QBBlvk1JylkX"
   },
   "source": [
    "# UCI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AmcpT5DDO2d"
   },
   "outputs": [],
   "source": [
    "def train_mc_dropout(data,\n",
    "                     drop_prob,\n",
    "                     num_epochs,\n",
    "                     num_units,\n",
    "                     learn_rate,\n",
    "                     weight_decay,\n",
    "                     train_metrics,\n",
    "                     test_metrics,\n",
    "                     batch_size):\n",
    "    \n",
    "    train_nll, test_nll = [], []\n",
    "    train_rmses, test_rmses = [], []\n",
    "    for metric in train_metrics:\n",
    "        metric.reset()        \n",
    "        \n",
    "    for metric in test_metrics:\n",
    "        metric.reset()\n",
    "\n",
    "    network = simple_regressor.Model(layer_sizes=[data.input_dim, num_units, 2],\n",
    "                                     device=device,\n",
    "                                     variance_transform=utils.variance_linear_asymptote(),\n",
    "                                     loss_function=custom_loss.gaussian_neg_log_likelihood_1d)\n",
    "    network.optimizer = torch.optim.SGD(network.parameters(),\n",
    "                                lr=learn_rate,\n",
    "                                weight_decay=weight_decay)\n",
    "    \n",
    "    prob_ensemble = create_ensemble(num_ensemble_members=args.num_ensemble_members,\n",
    "                               model=network,\n",
    "                               ensemble_output_size=1)\n",
    "    prob_ensemble.add_metrics(train_metrics)\n",
    "\n",
    "    x_train, y_train, x_test, y_test = data.create_train_val_split(0.9)\n",
    "\n",
    "    x_means, x_stds = x_train.mean(axis = 0), x_train.var(axis = 0)**0.5\n",
    "    y_means, y_stds = y_train.mean(axis = 0), y_train.var(axis = 0)**0.5\n",
    "\n",
    "    x_train = (x_train - x_means) / x_stds\n",
    "    y_train = (y_train - y_means) / y_stds\n",
    "\n",
    "    x_test = (x_test - x_means) / x_stds\n",
    "    y_test = (y_test - y_means) / y_stds\n",
    "    \n",
    "    if batch_size is None:\n",
    "        batch_size = x_train.shape[0]\n",
    "    trainloader = uci_base.uci_dataloader(x_train, y_train, batch_size)\n",
    "\n",
    "    losses = []\n",
    "    prob_ensemble.train(train_loader=trainloader,\n",
    "                        num_epochs=num_epochs)\n",
    "\n",
    "    mean_shift = None\n",
    "    std_scale = None\n",
    "    #mean_shift = y_means\n",
    "    #std_scale = y_stds\n",
    "\n",
    "    train_loss, train_rmse = get_loss_and_rmse(network,\n",
    "                                               network.loss,\n",
    "                                               x_train,\n",
    "                                               y_train,\n",
    "                                               mean_shift=mean_shift,\n",
    "                                               std_scale=std_scale)\n",
    "\n",
    "    test_loss, test_rmse = get_loss_and_rmse(network,\n",
    "                                             network.loss,\n",
    "                                             x_test,\n",
    "                                             y_test,\n",
    "                                             mean_shift=mean_shift,\n",
    "                                             std_scale=std_scale)\n",
    "\n",
    "    testloader = uci_base.uci_dataloader(x_test, y_test, len(y_test))\n",
    "    test_metrics, test_loss = network.test(testloader, test_metrics, network.loss)\n",
    "    \n",
    "    train_nll.append((train_loss.item()/len(x_train) + np.log(y_stds)[0]))\n",
    "    test_nll.append((test_loss.item()/len(x_test) + np.log(y_stds)[0]))\n",
    "\n",
    "    print(\"Train NLL\\t = {:.3f} +/- {:.3f}\".format(*mean_and_std_from_list(train_nll)))\n",
    "    print(\"Test  NLL\\t = {:.3f} +/- {:.3f}\".format(*mean_and_std_from_list(test_nll)))\n",
    "    print(\"Train RMSE\\t = {:.3f} +/- {:.3f}\".format(\n",
    "        *mean_and_std_from_metric(train_metrics[0], rescale=y_stds[0])))\n",
    "    print(\"Test RMSE\\t = {:.3f} +/- {:.3f}\".format(\n",
    "        *mean_and_std_from_metric(test_metrics[0], rescale=y_stds[0])))\n",
    "    return network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRPICBiXCegI"
   },
   "source": [
    "# Red wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4542,
     "status": "ok",
     "timestamp": 1558130529014,
     "user": {
      "displayName": "Stratis Markou",
      "photoUrl": "",
      "userId": "09754366312766083286"
     },
     "user_tz": -60
    },
    "id": "KOqgIBXcCegJ",
    "outputId": "21e7e896-5a30-4692-ff6d-72182f4b83b4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2020-02-12 09:10:12,075 INFO  Model           - Moving model to device: cuda\n",
      "2020-02-12 09:10:12,076 INFO  Model           - Using variance transform: <lambda>\n",
      "2020-02-12 09:10:12,077 WARNING Ensemble        - Is subclass check disabled\n",
      "2020-02-12 09:10:12,077 INFO  Ensemble        - Adding <class 'src.ensemble.simple_regressor.Model'> to ensemble\n",
      "2020-02-12 09:10:12,078 INFO  Ensemble        - Adding metric: RMSE\n",
      "2020-02-12 09:10:12,079 INFO  Ensemble        - Training ensemble\n",
      "2020-02-12 09:10:12,079 INFO  Ensemble        - Training member 1/1\n",
      "2020-02-12 09:10:12,093 INFO  Model           - Train - Epoch 1: Loss: 2128.920 RMSE: 0.991\n",
      "2020-02-12 09:10:12,113 INFO  Model           - Train - Epoch 2: Loss: 1966.156 RMSE: 0.934\n",
      "2020-02-12 09:10:12,127 INFO  Model           - Train - Epoch 3: Loss: 1898.120 RMSE: 0.902\n",
      "2020-02-12 09:10:12,141 INFO  Model           - Train - Epoch 4: Loss: 1854.375 RMSE: 0.878\n",
      "2020-02-12 09:10:12,155 INFO  Model           - Train - Epoch 5: Loss: 1822.426 RMSE: 0.860\n",
      "2020-02-12 09:10:12,177 INFO  Model           - Train - Epoch 6: Loss: 1797.584 RMSE: 0.845\n",
      "2020-02-12 09:10:12,191 INFO  Model           - Train - Epoch 7: Loss: 1777.695 RMSE: 0.833\n",
      "2020-02-12 09:10:12,206 INFO  Model           - Train - Epoch 8: Loss: 1761.530 RMSE: 0.824\n",
      "2020-02-12 09:10:12,221 INFO  Model           - Train - Epoch 9: Loss: 1748.234 RMSE: 0.817\n",
      "2020-02-12 09:10:12,236 INFO  Model           - Train - Epoch 10: Loss: 1737.196 RMSE: 0.811\n",
      "2020-02-12 09:10:12,250 INFO  Model           - Train - Epoch 11: Loss: 1727.921 RMSE: 0.807\n",
      "2020-02-12 09:10:12,265 INFO  Model           - Train - Epoch 12: Loss: 1720.021 RMSE: 0.803\n",
      "2020-02-12 09:10:12,279 INFO  Model           - Train - Epoch 13: Loss: 1713.185 RMSE: 0.800\n",
      "2020-02-12 09:10:12,295 INFO  Model           - Train - Epoch 14: Loss: 1707.202 RMSE: 0.798\n",
      "2020-02-12 09:10:12,310 INFO  Model           - Train - Epoch 15: Loss: 1701.906 RMSE: 0.796\n",
      "2020-02-12 09:10:12,328 INFO  Model           - Train - Epoch 16: Loss: 1697.146 RMSE: 0.794\n",
      "2020-02-12 09:10:12,344 INFO  Model           - Train - Epoch 17: Loss: 1692.815 RMSE: 0.793\n",
      "2020-02-12 09:10:12,361 INFO  Model           - Train - Epoch 18: Loss: 1688.829 RMSE: 0.792\n",
      "2020-02-12 09:10:12,378 INFO  Model           - Train - Epoch 19: Loss: 1685.129 RMSE: 0.790\n",
      "2020-02-12 09:10:12,394 INFO  Model           - Train - Epoch 20: Loss: 1681.675 RMSE: 0.789\n",
      "2020-02-12 09:10:12,410 INFO  Model           - Train - Epoch 21: Loss: 1678.423 RMSE: 0.788\n",
      "2020-02-12 09:10:12,426 INFO  Model           - Train - Epoch 22: Loss: 1675.342 RMSE: 0.788\n",
      "2020-02-12 09:10:12,442 INFO  Model           - Train - Epoch 23: Loss: 1672.422 RMSE: 0.787\n",
      "2020-02-12 09:10:12,458 INFO  Model           - Train - Epoch 24: Loss: 1669.654 RMSE: 0.786\n",
      "2020-02-12 09:10:12,478 INFO  Model           - Train - Epoch 25: Loss: 1667.005 RMSE: 0.785\n",
      "2020-02-12 09:10:12,532 INFO  Model           - Train - Epoch 26: Loss: 1664.466 RMSE: 0.784\n",
      "2020-02-12 09:10:12,548 INFO  Model           - Train - Epoch 27: Loss: 1662.037 RMSE: 0.784\n",
      "2020-02-12 09:10:12,568 INFO  Model           - Train - Epoch 28: Loss: 1659.701 RMSE: 0.783\n",
      "2020-02-12 09:10:12,584 INFO  Model           - Train - Epoch 29: Loss: 1657.452 RMSE: 0.782\n",
      "2020-02-12 09:10:12,602 INFO  Model           - Train - Epoch 30: Loss: 1655.290 RMSE: 0.782\n",
      "2020-02-12 09:10:12,620 INFO  Model           - Train - Epoch 31: Loss: 1653.198 RMSE: 0.781\n",
      "2020-02-12 09:10:12,638 INFO  Model           - Train - Epoch 32: Loss: 1651.182 RMSE: 0.781\n",
      "2020-02-12 09:10:12,654 INFO  Model           - Train - Epoch 33: Loss: 1649.236 RMSE: 0.780\n",
      "2020-02-12 09:10:12,671 INFO  Model           - Train - Epoch 34: Loss: 1647.349 RMSE: 0.780\n",
      "2020-02-12 09:10:12,689 INFO  Model           - Train - Epoch 35: Loss: 1645.519 RMSE: 0.779\n",
      "2020-02-12 09:10:12,706 INFO  Model           - Train - Epoch 36: Loss: 1643.757 RMSE: 0.779\n",
      "2020-02-12 09:10:12,723 INFO  Model           - Train - Epoch 37: Loss: 1642.053 RMSE: 0.778\n",
      "2020-02-12 09:10:12,739 INFO  Model           - Train - Epoch 38: Loss: 1640.396 RMSE: 0.778\n",
      "2020-02-12 09:10:12,755 INFO  Model           - Train - Epoch 39: Loss: 1638.794 RMSE: 0.777\n",
      "2020-02-12 09:10:12,771 INFO  Model           - Train - Epoch 40: Loss: 1637.228 RMSE: 0.777\n",
      "Train NLL\t = 0.919 +/- 0.000\n",
      "Test  NLL\t = 1.020 +/- 0.000\n",
      "Train RMSE\t = 0.625 +/- nan\n",
      "Test RMSE\t = 0.689 +/- nan\n"
     ]
    }
   ],
   "source": [
    "wine_data = wine.WineData(\"data/uci/wine/winequality-red.csv\")\n",
    "net = train_mc_dropout(data=wine_data,\n",
    "                       drop_prob=0.0,\n",
    "                       num_epochs=40,\n",
    "                       num_units=50,\n",
    "                       learn_rate=1e-4,\n",
    "                       weight_decay=0.0, #1e-1/len(data)**0.5,\n",
    "                       train_metrics=train_metrics,\n",
    "                       test_metrics=test_metrics,\n",
    "                       batch_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CA4b-sP4eBJw"
   },
   "source": [
    "# Housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5232,
     "status": "ok",
     "timestamp": 1558130359147,
     "user": {
      "displayName": "Stratis Markou",
      "photoUrl": "",
      "userId": "09754366312766083286"
     },
     "user_tz": -60
    },
    "id": "UXsgiUziqh9w",
    "outputId": "0b125922-91ea-4c97-904b-c6c6197e2a80"
   },
   "outputs": [],
   "source": [
    "bost_data = bost.BostonData(\"data/uci/bost/housing.data\")\n",
    "train_mc_dropout(data=bost_data,\n",
    "                 drop_prob=0.0,\n",
    "                 num_epochs=40,\n",
    "                 num_units=50,\n",
    "                 learn_rate=1e-4,\n",
    "                 weight_decay=0.0, #1e-1/len(data)**0.5,\n",
    "                 train_metrics=train_metrics,\n",
    "                 test_metrics=test_metrics,\n",
    "                 batch_size=None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mc_dropout_heteroscedastic.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
