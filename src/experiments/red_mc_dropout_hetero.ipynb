{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 258
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10811,
     "status": "ok",
     "timestamp": 1558128143256,
     "user": {
      "displayName": "Stratis Markou",
      "photoUrl": "",
      "userId": "09754366312766083286"
     },
     "user_tz": -60
    },
    "id": "xAYPKSFrG8AF",
    "outputId": "cf3df00b-2fcc-48ba-bd75-af624f50aa20"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir(\"/home/jakob/doktor/projects/EnsembleUncertainty/code\")\n",
    "\"\"\"Learing \"logit\" distribution in regression example\"\"\"\n",
    "import logging\n",
    "import zipfile\n",
    "from copy import copy, deepcopy\n",
    "import urllib.request\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable\n",
    "from torch.optim import Optimizer\n",
    "from torch.optim.sgd import SGD\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import make_grid\n",
    "from sklearn.model_selection import KFold\n",
    "from src.dataloaders.uci import uci_base, wine, bost\n",
    "from src import metrics\n",
    "from src import utils\n",
    "from src.ensemble import simple_regressor, ensemble\n",
    "from src import loss as custom_loss\n",
    "\n",
    "\n",
    "\n",
    "LOGGER = logging.getLogger(__name__)\n",
    "EXPERIMENT_NAME = \"red_regression_logits\"\n",
    "\n",
    "# Settings\n",
    "class Args():\n",
    "    pass\n",
    "args = Args()\n",
    "args.seed = 1\n",
    "args.gpu = False\n",
    "args.log_dir = Path(\"./logs\")\n",
    "args.log_level = logging.INFO\n",
    "args.retrain = True\n",
    "\n",
    "args.num_ensemble_members=1\n",
    "args.num_epochs=1\n",
    "args.lr = 0.01\n",
    "\n",
    "# General constructs\n",
    "train_metrics = list()\n",
    "test_metrics = list()\n",
    "\n",
    "rmse = metrics.Metric(name=\"RMSE\", function=metrics.root_mean_squared_error)\n",
    "train_metrics.append(deepcopy(rmse))\n",
    "test_metrics.append(rmse)\n",
    "\n",
    "BATCH_SIZE = 32\n",
    "torch.cuda.device(0)\n",
    "torch.cuda.get_device_name(torch.cuda.current_device())\n",
    "device = torch.device(\"cuda\")\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%config InlineBackend.figure_format = 'svg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "_1S5kt0omQ-N"
   },
   "outputs": [],
   "source": [
    "def to_variable(var=(), cuda=True, volatile=False):\n",
    "    out = []\n",
    "    for v in var:\n",
    "        \n",
    "        if isinstance(v, np.ndarray):\n",
    "            v = torch.from_numpy(v).type(torch.FloatTensor)\n",
    "\n",
    "        if not v.is_cuda and cuda:\n",
    "            v = v.cuda()\n",
    "\n",
    "        if not isinstance(v, Variable):\n",
    "            v = Variable(v, volatile=volatile)\n",
    "\n",
    "        out.append(v)\n",
    "    return out\n",
    "\n",
    "def get_loss_and_rmse(network,\n",
    "                      loss_function,\n",
    "                      x, y,\n",
    "                      mean_shift=None, std_scale=None):\n",
    "    x, y = to_variable(var=(x, y), cuda=True)\n",
    "\n",
    "    logits = network.forward(x)\n",
    "    output = network.transform_logits(logits)\n",
    "    mean, std = output\n",
    "\n",
    "    if mean_shift is not None and std_scale is not None:\n",
    "        mean_shift = torch.tensor(mean_shift).float().cuda()\n",
    "        std_scale = torch.tensor(std_scale).float().cuda()\n",
    "        mean = mean * std_scale + mean_shift\n",
    "        y = y * std_scale + mean_shift\n",
    "        std *= std_scale\n",
    "\n",
    "    loss = loss_function((mean, std), y)\n",
    "\n",
    "    rmse = ((mean - y)**2).mean()**0.5\n",
    "\n",
    "    return loss.detach().cpu(), rmse.detach().cpu()\n",
    "\n",
    "def create_ensemble(num_ensemble_members,\n",
    "                    model,\n",
    "                    ensemble_output_size):\n",
    "    prob_ensemble = ensemble.Ensemble(ensemble_output_size)\n",
    "    for _ in range(num_ensemble_members):\n",
    "        prob_ensemble.add_member(copy(model))\n",
    "    return prob_ensemble\n",
    "\n",
    "def mean_and_std_from_list(samples):\n",
    "    \"\"\"Calculate mean and std from np-array compatible list\"\"\"\n",
    "    array = np.array(samples)\n",
    "    return array.mean(), array.std()\n",
    "\n",
    "def mean_and_std_from_metric(metric, rescale=1):\n",
    "    \"\"\"Calculate mean and std from np-array compatible list\"\"\"\n",
    "    return metric.mean() * rescale, metric.std() * rescale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "QBBlvk1JylkX"
   },
   "source": [
    "# UCI datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "0AmcpT5DDO2d"
   },
   "outputs": [],
   "source": [
    "def train_mc_dropout(data,\n",
    "                     drop_prob,\n",
    "                     num_epochs,\n",
    "                     num_units,\n",
    "                     learn_rate,\n",
    "                     weight_decay,\n",
    "                     train_metrics,\n",
    "                     test_metrics,\n",
    "                     batch_size):\n",
    "    \n",
    "    train_nll, test_nll = [], []\n",
    "    train_rmses, test_rmses = [], []\n",
    "    for metric in train_metrics:\n",
    "        metric.reset()        \n",
    "        \n",
    "    for metric in test_metrics:\n",
    "        metric.reset()\n",
    "\n",
    "    network = simple_regressor.Model(layer_sizes=[data.input_dim, num_units, 2],\n",
    "                                     device=device,\n",
    "                                     variance_transform=utils.variance_linear_asymptote(),\n",
    "                                     loss_function=custom_loss.gaussian_neg_log_likelihood_1d)\n",
    "    network.optimizer = torch.optim.SGD(network.parameters(),\n",
    "                                lr=learn_rate,\n",
    "                                weight_decay=weight_decay)\n",
    "    \n",
    "    prob_ensemble = create_ensemble(num_ensemble_members=args.num_ensemble_members,\n",
    "                               model=network,\n",
    "                               ensemble_output_size=1)\n",
    "    prob_ensemble.add_metrics(train_metrics)\n",
    "\n",
    "    x_train, y_train, x_test, y_test = data.create_train_val_split(0.9)\n",
    "\n",
    "    x_means, x_stds = x_train.mean(axis = 0), x_train.var(axis = 0)**0.5\n",
    "    y_means, y_stds = y_train.mean(axis = 0), y_train.var(axis = 0)**0.5\n",
    "\n",
    "    x_train = (x_train - x_means) / x_stds\n",
    "    y_train = (y_train - y_means) / y_stds\n",
    "\n",
    "    x_test = (x_test - x_means) / x_stds\n",
    "    y_test = (y_test - y_means) / y_stds\n",
    "    \n",
    "    if batch_size is None:\n",
    "        batch_size = x_train.shape[0]\n",
    "    trainloader = uci_base.uci_dataloader(x_train, y_train, batch_size)\n",
    "\n",
    "    losses = []\n",
    "    prob_ensemble.train(train_loader=trainloader,\n",
    "                        num_epochs=num_epochs)\n",
    "\n",
    "\n",
    "    mean_shift = None\n",
    "    std_scale = None\n",
    "    #mean_shift = y_means\n",
    "    #std_scale = y_stds\n",
    "\n",
    "    train_loss, train_rmse = get_loss_and_rmse(network,\n",
    "                                               network.loss,\n",
    "                                               x_train,\n",
    "                                               y_train,\n",
    "                                               mean_shift=mean_shift,\n",
    "                                               std_scale=std_scale)\n",
    "\n",
    "    test_loss, test_rmse = get_loss_and_rmse(network,\n",
    "                                             network.loss,\n",
    "                                             x_test,\n",
    "                                             y_test,\n",
    "                                             mean_shift=mean_shift,\n",
    "                                             std_scale=std_scale)\n",
    "\n",
    "    testloader = uci_base.uci_dataloader(x_test, y_test, len(y_test))\n",
    "\n",
    "    test_metrics, test_loss = network.test(testloader, test_metrics, network.loss)\n",
    "    train_nll.append((train_loss.cpu().data.numpy()/len(x_train) + np.log(y_stds)[0]))\n",
    "    test_nll.append((test_loss.cpu().data.numpy()/len(x_test) + np.log(y_stds)[0]))\n",
    "\n",
    "    train_rmses.append(y_stds[0]*train_rmse.cpu().data.numpy())\n",
    "    test_rmses.append(y_stds[0]*test_rmse.cpu().data.numpy())\n",
    "\n",
    "    print(\"Train NLL\\t = {:.3f} +/- {:.3f}\".format(*mean_and_std_from_list(train_nll)))\n",
    "    print(\"Test  NLL\\t = {:.3f} +/- {:.3f}\".format(*mean_and_std_from_list(test_nll)))\n",
    "    print(\"Train RMSE\\t = {:.3f} +/- {:.3f}\".format(\n",
    "        *mean_and_std_from_metric(train_metrics[0], rescale=y_stds[0])))\n",
    "    print(\"Test RMSE\\t = {:.3f} +/- {:.3f}\".format(\n",
    "        *mean_and_std_from_metric(test_metrics[0], rescale=y_stds[0])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "HRPICBiXCegI"
   },
   "source": [
    "# Red wine dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4542,
     "status": "ok",
     "timestamp": 1558130529014,
     "user": {
      "displayName": "Stratis Markou",
      "photoUrl": "",
      "userId": "09754366312766083286"
     },
     "user_tz": -60
    },
    "id": "KOqgIBXcCegJ",
    "outputId": "21e7e896-5a30-4692-ff6d-72182f4b83b4"
   },
   "outputs": [],
   "source": [
    "wine_data = wine.WineData(\"data/uci/wine/winequality-red.csv\")\n",
    "train_mc_dropout(data=wine_data,\n",
    "                       drop_prob=0.0,\n",
    "                       num_epochs=40,\n",
    "                       num_units=50,\n",
    "                       learn_rate=1e-4,\n",
    "                       weight_decay=0.0, #1e-1/len(data)**0.5,\n",
    "                       train_metrics=train_metrics,\n",
    "                       test_metrics=test_metrics,\n",
    "                       batch_size=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "CA4b-sP4eBJw"
   },
   "source": [
    "# Housing dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 765
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 5232,
     "status": "ok",
     "timestamp": 1558130359147,
     "user": {
      "displayName": "Stratis Markou",
      "photoUrl": "",
      "userId": "09754366312766083286"
     },
     "user_tz": -60
    },
    "id": "UXsgiUziqh9w",
    "outputId": "0b125922-91ea-4c97-904b-c6c6197e2a80"
   },
   "outputs": [],
   "source": [
    "bost_data = bost.BostonData(\"data/uci/bost/housing.data\")\n",
    "train_mc_dropout(data=bost_data,\n",
    "                 drop_prob=0.0,\n",
    "                 num_epochs=40,\n",
    "                 num_units=50,\n",
    "                 learn_rate=1e-4,\n",
    "                 weight_decay=0.0, #1e-1/len(data)**0.5,\n",
    "                 train_metrics=train_metrics,\n",
    "                 test_metrics=test_metrics,\n",
    "                 batch_size=None)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "mc_dropout_heteroscedastic.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
